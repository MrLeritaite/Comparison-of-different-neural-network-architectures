# -*- coding: utf-8 -*-
"""covid-train-25-epochs-heavy-aug.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11wRoc5g_71WGwWEBucrpSooeuL8darot
"""

!nvidia-smi

"""# auxillary installation"""

from google.colab import drive
drive.mount('/content/drive')

#COVID-19_Radiography_Dataset
import zipfile
with zipfile.ZipFile("/content/drive/MyDrive/Covid-Normal-Pneumonia/archive.zip", 'r') as zip_ref:
    zip_ref.extractall("/content")

#metadata csv
import zipfile
with zipfile.ZipFile("/content/drive/MyDrive/Covid-Normal-Pneumonia/archive(1).zip", 'r') as zip_ref:
    zip_ref.extractall("/content")

#chest_xray
import zipfile
with zipfile.ZipFile("/content/drive/MyDrive/Covid-Normal-Pneumonia/archive(2).zip", 'r') as zip_ref:
    zip_ref.extractall("/content")

#dataset generated_dataset and some files
import zipfile
with zipfile.ZipFile("/content/drive/MyDrive/Covid-Normal-Pneumonia/archive(3).zip", 'r') as zip_ref:
    zip_ref.extractall("/content")

#xray_dataset_covid19
import zipfile
with zipfile.ZipFile("/content/drive/MyDrive/Covid-Normal-Pneumonia/archive(4).zip", 'r') as zip_ref:
    zip_ref.extractall("/content")

!pip install -q timm
!pip install -q openpyxl
!pip install wandb

!pip install -U albumentations
!pip install -U git+https://github.com/qubvel/efficientnet
!pip install -U efficientnet

"""# libararies """

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import os 
import sys 
from tqdm.notebook import tqdm 
import seaborn as sns 
import plotly
import random 
from glob import glob

import time
import cv2 
from PIL import Image
import imageio
from sklearn.utils import shuffle

from sklearn.metrics import roc_auc_score,f1_score ,accuracy_score , precision_score , f1_score , recall_score
from sklearn.model_selection import StratifiedKFold ,GroupKFold , train_test_split

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset , DataLoader
import albumentations 
from albumentations import *

import plotly
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

import gc
import timm
import sys
import warnings
import wandb
warnings.filterwarnings("ignore")
#wandb.login()

"""# config"""

cfg = {
    'fold':5,
    'seed':2021,
    'epochs':25,
    'train_bs':44,
    'valid_bs':44,
    'num_workers':8,
    'backbone': "resnet200d",
    'base_lr':1e-3,
    'patience':5,
    'test_bs':16,
    'min_lr':1e-9,
    'optimizer':'adam',
    'image_size':256,
    'use_amp': True
}

device = ('cuda' if torch.cuda.is_available() else 'cpu')

"""# data loading

# a. Covid data loading
"""

covid_images1 = pd.read_csv('/content/metadata.csv')
covid_path = []
for i in range(covid_images1.shape[0]):
    if covid_images1['finding'][i] == 'COVID-19':
        covid_path.append(covid_images1['filename'][i])
for i in range(len(covid_path)):
    covid_path[i] = '/content/images/'+covid_path[i]
covid1 = pd.DataFrame()
covid1['PATH']=covid_path
covid1['FILE NAME'] = 'Covid'
covid1['SIZE'] = '256*256'
for i in range(covid1.shape[0]):
    if covid1['PATH'][i].endswith('gz'):
        covid1= covid1.drop(labels = i,axis = 0)
covid2 = pd.read_excel('/content/COVID-19_Radiography_Dataset/COVID.metadata.xlsx',engine = 'openpyxl')
covid2 = covid2.drop(['FORMAT'],axis = 1)
covid2 = covid2.rename(columns = {'URL':'PATH'})
for i in range(covid2.shape[0]):
    if covid2['FILE NAME'][i].startswith('COVID-'):
        name = covid2['FILE NAME'][i]
        covid2['PATH'][i] = f'/content/COVID-19_Radiography_Dataset/COVID/{name}.png'

covid2['FILE NAME'] = 'Covid'
covid = pd.concat([covid1,covid2],axis = 0).reset_index(drop = True)
covid

"""# b. Normal data loading """

normal1 = pd.DataFrame()
normal_path1 = glob('/content/chest_xray/train/NORMAL/*jpeg')
normal1['PATH'] = normal_path1
normal1['FILE NAME'] = 'Normal'
normal1['SIZE'] = '1024*1024'

normal2 = pd.DataFrame()
normal_path2 = glob('/content/chest_xray/test/NORMAL/*jpeg')
normal2['PATH'] = normal_path2
normal2['FILE NAME'] = 'Normal'
normal2['SIZE'] = '1024*1024'
normal3_ = pd.DataFrame()
normal3 = glob('/content/COVID-19_Radiography_Dataset/Normal/*')
normal3_['PATH'] = normal3
normal3_['FILE NAME'] = 'Normal'
normal3_['SIZE'] = '1024*1024'
normal = pd.concat([normal1,normal2,normal3_],axis=0).reset_index(drop = True)
normal

"""# c. Pneumonia data loading  """

pneumonia1 = pd.DataFrame()
pneumonia_path1 = glob('/content/chest_xray/train/PNEUMONIA/*jpeg')
pneumonia1['PATH'] = pneumonia_path1
pneumonia1['FILE NAME'] = 'Pneumonia'
pneumonia1['SIZE'] = '1024*1024'

pneumonia2 = pd.DataFrame()
pneumonia_path2 = glob('/content/chest_xray/test/PNEUMONIA/*jpeg')
pneumonia2['PATH'] = pneumonia_path2
pneumonia2['FILE NAME'] = 'Pneumonia'
pneumonia2['SIZE'] = '1024*1024'

pneumonia3 = pd.DataFrame()
pne3 = glob('/content/COVID-19_Radiography_Dataset/Viral Pneumonia/*')
pneumonia3['PATH'] = pne3
pneumonia3['FILE NAME'] = 'Pneumonia'
pneumonia3['SIZE'] = '1024*1024'

pneumonia = pd.concat([pneumonia1,pneumonia2,pneumonia3],axis = 0).reset_index(drop = True)
pneumonia

"""# d. Merging all the classes"""

data = pd.concat([covid,pneumonia,normal],axis = 0).reset_index(drop = True)
data = shuffle(data).reset_index(drop = True)
data

data['FILE NAME'].value_counts().plot(kind = 'bar')

"""# Helper function """

def plotter(imgs,cols = 3 , cmap = 'inferno',size=10, is_rgb=True,title = ''):
    rows = len(imgs)// cols+1
    fig = plt.figure(figsize=(cols*size, rows*size))
    for i, img in enumerate(imgs):
        fig.add_subplot(rows, cols, i+1)
        plt.imshow(img, cmap=cmap)
    plt.suptitle(title,fontsize=30)

def load_images(image_path):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    return img

img = load_images('/content/COVID-19_Radiography_Dataset/Normal/Normal-100.png')
plt.imshow(img,cmap='gray')

"""# 1. Image data EDA

# lets take a look at covid images
"""

covid_path = [covid['PATH'][0],covid['PATH'][4],covid['PATH'][320],covid['PATH'][450],covid['PATH'][50]
              ,covid['PATH'][2],covid['PATH'][1],covid['PATH'][110]
             ,covid['PATH'][5]]

covid_images = []
for p in covid_path:
    covid_images.append(plt.imread(p))
plotter(covid_images ,title = 'covid_patient',cmap = 'bone')

"""# Now viral pneumonia images"""

pne_patient_path = [pneumonia['PATH'][0],pneumonia['PATH'][4],pneumonia['PATH'][320],pneumonia['PATH'][450],pneumonia['PATH'][50]
              ,pneumonia['PATH'][2],pneumonia['PATH'][1],pneumonia['PATH'][110]
             ,pneumonia['PATH'][5]]
pneu_images = []
for p in pne_patient_path:
    pneu_images.append(plt.imread(p))
plotter(pneu_images,title = 'Pneumonia_infected_patient',cmap = 'bone')

"""# Now the normal images"""

normal_patient_path = [normal['PATH'][0],normal['PATH'][4],normal['PATH'][320],normal['PATH'][450],normal['PATH'][50]
              ,normal['PATH'][2],normal['PATH'][1],normal['PATH'][110]
             ,normal['PATH'][5]]
normal_images = []
for p in normal_patient_path:
    normal_images.append(plt.imread(p))
plotter(normal_images,title = 'Normal_patient',cmap = 'bone')

"""# Tabular data EDA"""

data

"""1. from looking above in the data frame we found that there is no class section indeed it has File Name which tells what class the image belongs to hence we will have to fix that first
2. And as we look more in the dataset there is no other tabular data that will be helful for the model hence it will be a classic Computer Vision problem , unlike tabular + image model 
"""

#train = train.loc[:10000,:]
data = data.rename(columns = {'FILE NAME':'Class'})
#px.bar(data,x ='Class',title = 'Class distribution vs Image size available', color = 'SIZE')

"""from looking at the bargraph we can see that the data is highly imbalanced and we also found out that we have covid images of size 256 by 256 pixels and normal and pneumonia images of size 1024 by 1024 pixels"""

# setting up labels / targets

data['Targets'] = 0

for i in range(data.shape[0]):
    if data['Class'][i] == 'Covid':
        data['Targets'][i] = 1
    elif data['Class'][i] == 'Pneumonia':
        data['Targets'][i] = 0
    elif data['Class'][i] == 'Normal':
        data['Targets'][i] = 0
data

"""# 3. Model build up

# a. Setting up seeds
"""

def seed_everything(seed):
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True # for faster training, but not deterministic

seed_everything(cfg['seed'])

"""# b. augmentations """

transforms_train = albumentations.Compose([
   albumentations.RandomResizedCrop(cfg['image_size'], cfg['image_size'], scale=(0.9, 1), p=1), 
   albumentations.HorizontalFlip(p=0.5),
   albumentations.ShiftScaleRotate(p=0.5),
   albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.5),
   albumentations.RandomBrightnessContrast(brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2), p=0.5),
   albumentations.CLAHE(clip_limit=(1,4), p=0.5),
   albumentations.OneOf([
       albumentations.OpticalDistortion(distort_limit=1.0),
       albumentations.GridDistortion(num_steps=5, distort_limit=1.),
       albumentations.ElasticTransform(alpha=3),
   ], p=0.2),
   albumentations.OneOf([
       albumentations.GaussNoise(var_limit=[10, 50]),
       albumentations.GaussianBlur(),
       albumentations.MotionBlur(),
       albumentations.MedianBlur(),
   ], p=0.2),
  albumentations.OneOf([
      JpegCompression(),
      Downscale(scale_min=0.1, scale_max=0.15),
  ], p=0.2),
  IAAPiecewiseAffine(p=0.2),
  IAASharpen(p=0.2),
  albumentations.Cutout(max_h_size=int(cfg['image_size'] * 0.1), max_w_size=int(cfg['image_size']* 0.1), num_holes=5, p=0.5),
  albumentations.Normalize(),
])

transforms_valid = albumentations.Compose([
    albumentations.Resize(cfg['image_size'], cfg['image_size']),
    albumentations.Normalize()
])

"""# c. Dataset"""

class covid_classifier_dataset(Dataset):
    def __init__(self,
                 df,
                augmentations = None
                ):
        super().__init__()
        self.df = df 
        self.augmentations  = augmentations 
    
    def __len__(self):
        return self.df.shape[0]
    
    def __getitem__(self,idx):
        label = self.df['Targets'][idx]
        img = cv2.imread(self.df['PATH'][idx])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        if self.augmentations  is not None:
            res = self.augmentations(image = img)
            img = res['image']
        img = img.astype(np.float32)
        img = img.transpose(2,0,1)
       # img = torch.tensor(img).float()
        
        return img,label

"""# d. Dataloader"""

def covid_dataloader(data,train_idx,valid_idx):
    train_ = data.iloc[train_idx,:].reset_index(drop = True)
    train_dataset = covid_classifier_dataset(train_,augmentations  = transforms_train )
    train_loader = DataLoader(train_dataset,batch_size = cfg['train_bs'],shuffle = True,
                              num_workers = cfg['num_workers'],pin_memory = False,
                              drop_last = False
                             )
    
    valid_ = data.iloc[valid_idx,:].reset_index(drop = True)
    valid_dataset = covid_classifier_dataset(valid_,augmentations  = transforms_valid)
    valid_loader = DataLoader(valid_dataset,batch_size = cfg['valid_bs'],shuffle = False,
                             num_workers = cfg['num_workers'],pin_memory = False)
    
    return train_loader , valid_loader

"""# f. Train one epoch """

def train_one_epoch(train_loader,model,optimizer,loss_fun,device,scheduler,epoch):
    model.train()
    t = time.time()
    losses = []
    image_preds_all = []
    image_targets_all = []
    loss = 0.0
    acc = 0.0
    accuracy = 0.0
    f1 = 0.0
    recall = 0
    precision = 0.0
    if  cfg['use_amp']:
        scaler = torch.cuda.amp.GradScaler()
    pbar = tqdm(enumerate(train_loader),total = len(train_loader))
    for step ,(images,labels) in pbar:
     #   labels = labels.unsqueeze(1)
        images, labels = images.to(device,dtype = torch.float32), labels.to(device,dtype = torch.long)
        PREDS = []
        TARGETS = []
        if cfg['use_amp']:
            with torch.cuda.amp.autocast():
                logits = model(images)
                image_preds_all += [torch.argmax(logits, 1).detach().cpu().numpy()]
                image_targets_all += [labels.detach().cpu().numpy()]
                PREDS.append(logits.detach().cpu().numpy())
                TARGETS.append(labels.detach().cpu().numpy())
                loss = loss_fun(logits,labels)
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
                scheduler.step()
                optimizer.zero_grad()
        
        else:
            logits = model(images)
            image_preds_all += [torch.argmax(logits, 1).detach().cpu().numpy()]
            image_targets_all += [labels.detach().cpu().numpy()]
            PREDS.append(logits.detach().cpu().numpy())
            TARGETS.append(labels.detach().cpu().numpy())
            loss = loss_fun(logits, labels)
            loss.backward()
            optimizer.step()
            scheduler.step()
            optimizer.zero_grad()
        losses.append(loss.item())
        TARGETS = np.concatenate(TARGETS)
        PREDS = np.concatenate(PREDS)
        acc = np.mean(PREDS.argmax(axis=0) == TARGETS)
        pbar.set_description(f'E:{epoch} loss: {loss.item():.5f},acc :{acc:.3f}')
  
            
 
    losses = np.mean(losses) 
    image_preds_all = np.concatenate(image_preds_all)
    image_targets_all = np.concatenate(image_targets_all)
    accuracy = accuracy_score(image_targets_all,image_preds_all)
    f1 = f1_score(image_targets_all,image_preds_all,average='macro')
    precision = precision_score(image_targets_all , image_preds_all,average='macro')
    recall = recall_score(image_targets_all , image_preds_all,average='macro')
   
  #  accuracy = (image_preds_all == image_targets_all).mean()
    return losses , accuracy  , f1 , precision , recall

"""# g. Validate one epoch """

def validate_one_epoch(valid_loader,loss_fun,model,device,epoch):
    t = time.time()
    accuracy = 0.0
    loss = 0.0
    f1 = 0.0
    recall = 0.0
    precision = 0.0
    losses = []
    image_preds_all = []
    image_targets_all = []
    pbar = tqdm(enumerate(valid_loader),total = len(valid_loader))
    for step , (images,labels) in pbar:
      #  labels = labels.unsqueeze(1)
        images , labels = images.to(device,dtype = torch.float32) , labels.to(device,dtype = torch.long)
        PREDS = []
        TARGETS = []
        with torch.no_grad():
            logits = model (images)
            image_preds_all += [torch.argmax(logits, 1).detach().cpu().numpy()]
            image_targets_all += [labels.detach().cpu().numpy()]
            PREDS.append(logits.detach().cpu().numpy())
            TARGETS.append(labels.detach().cpu().numpy())
            loss = loss_fun(logits,labels)
        losses.append(loss.item())
        TARGETS = np.concatenate(TARGETS)
        PREDS = np.concatenate(PREDS)
        acc = np.mean(PREDS.argmax(axis=0) == TARGETS)
        pbar.set_description(f'E:{epoch},loss: {loss.item():.5f},acc :{acc:.3f}')
      
    losses = np.mean(losses)
    image_preds_all  = np.concatenate(image_preds_all)
    image_targets_all = np.concatenate(image_targets_all)
    accuracy = accuracy_score(image_targets_all,image_preds_all)
    f1 = f1_score(image_targets_all,image_preds_all,average='macro')
    precision = precision_score(image_targets_all , image_preds_all,average='macro')
    recall = recall_score(image_targets_all , image_preds_all,average='macro')
   # accuracy = (image_preds_all == image_targets_all).mean()
    return losses , accuracy ,f1 , precision , recall

"""# Engine """

data

def engine(number_of_splits):
    folds = StratifiedKFold(n_splits = number_of_splits,random_state = cfg['seed'], shuffle = True).split(data['PATH'],data['Targets'])
    for fold,(train_idx,valid_idx) in enumerate(folds):
        if fold > 0:
            break
        print('Training with {} fold:{} started'.format(device,fold))
        print(f"We have {len(train_idx)} training images, and {len(valid_idx)} validation images")
        
        
        # model 
      #  model = my_model(cfg['backbone'],3,pretrained = True)
        model = timm.create_model(cfg['backbone'], pretrained=True)
        num_features = model.fc.in_features
        model.fc = nn.Linear(num_features, 3)
        model = model.to(device)
        
        # loss_function 
       # loss_fun = nn.BCEWithLogitsLoss()
        loss_fun= nn.CrossEntropyLoss()
       # loss_fun = nn.NLLLoss()
        # loss_fun = nn.LogSoftmax()
       # loss_fun = nn.BCELoss()
        
        # wandb 
   #     wandb.init(project=""+f"covid19_classifier_{fold}", config=cfg)
   #     wandb.watch(model, loss_fun, log="all", log_freq=10)
   #     log = {}
    
        # optimizer 
        optimizer = torch.optim.Adam(model.parameters(),lr = cfg['base_lr'])
        
        # scheduler 
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 10)
        
        # train_loader , valid_loader
        train_loader,valid_loader = covid_dataloader(data,train_idx,valid_idx)
        
        # parameters 
        f1_threshold = 0.92
        validation = 0.0
        
        
        for epoch in range(cfg['epochs']):
            
            # training 
            train_loss , train_accuracy  ,train_f1_score , train_precision , train_recall = train_one_epoch(train_loader,model,optimizer,loss_fun,device,scheduler,epoch)
            print(f'Epoch: {epoch} Train loss : {train_loss} , Train_accuracy :{train_accuracy} , train_precision :{train_precision} , train_recall:{train_recall} , train_f1_score:{train_f1_score}')
       #     wandb.log({"train_loss": train_loss})
       #     wandb.log({'train_accuracy':train_accuracy})
       #     wandb.log({"train_precision": train_precision})
       #     wandb.log({'train_recall':train_recall})
       #     wandb.log({'train_f1_score':train_f1_score})
            
            
            
            
            # validating 
            valid_loss , valid_accuracy ,valid_f1_score , valid_precision , valid_recall= validate_one_epoch(valid_loader,loss_fun,model ,device,epoch)
            print(f'Epoch: {epoch} Valid loss : {valid_loss} , valid_accuracy : {valid_accuracy} valid_precision :{valid_precision} , valid_recall:{valid_recall} , valid_f1_score:{valid_f1_score}')
       #     wandb.log({"valid_loss": valid_loss})
       #     wandb.log({"valid_accuracy": valid_accuracy})
       #     wandb.log({"valid_precision": valid_precision})
       #     wandb.log({'valid_recall':valid_recall})
       #     wandb.log({'valid_f1_score':valid_f1_score})
            backbone = cfg['backbone']
            
            if valid_f1_score > validation:
                print(f'Validation f1 score improved from {validation} to {valid_f1_score}')
                validation = valid_f1_score
                if validation > f1_threshold:
                    print('validation beat our threshold hence saving the model weights ')
                    torch.save(model.state_dict(),f'Covid_classifier_{backbone}_fold{fold}_validf1{validation}.pth')
            
        torch.save(model.state_dict(),f'Covid_classifier_{backbone}_final.pth')
        return train_accuracy, valid_accuracy,train_f1_score, valid_f1_score

"""# lets run the engine 

"""

train_acc, valid_acc, train_f1_score, valid_f1_score = engine(cfg['fold'])

gc.collect()

import matplotlib
import matplotlib.pyplot as plt

fig = plt.figure(figsize=(15, 7))
ax = fig.add_subplot()

fig.subplots_adjust(top=0.85)

ax.set_xlabel('Chest X-Ray Accuracy')
ax.set_ylabel('Average Models F1 score')

ax.plot(train_f1_score, train_acc, 'o', markersize=12, color='pink')
ax.annotate('Resnet200d', xy=(train_f1_score , train_acc), xytext=( train_f1_score +0.001, train_acc + 0.001))
plt.show()

valid_f1_score, train_acc

!git clone https://github.com/sayakpaul/Sharpness-Aware-Minimization-TensorFlow

import sys
sys.path.append("Sharpness-Aware-Minimization-TensorFlow")

import os
import shutil
import zipfile
import random
import matplotlib.pyplot as plt
import cv2
import time
import sys
import tensorflow as tf

import matplotlib.pyplot as plt
import resnet_cifar10
import utils
import time

from keras import layers
from keras import models
from keras.preprocessing.image import ImageDataGenerator
from keras.utils import to_categorical
from keras import optimizers

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from imutils import paths
import matplotlib.pyplot as plt
import numpy as np
import argparse
import cv2
import os


tf.random.set_seed(42)
print(tf.__version__)

try: # detect TPUs
    tpu = None
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
except ValueError: # detect GPUs
    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines
  
print("Number of accelerators: ", strategy.num_replicas_in_sync)

len(data) - len(data) // 3

len(data)

final_img = []
label = []

data_train_path_5000 = data["PATH"][:5000]
data_train_targets_5000 = data["Targets"][:5000]
for (i ,j) in zip(data_train_path_5000, data_train_targets_5000):
  label.append(j)
  img = cv2.imread(i)
  img = cv2.cvtColor(img ,cv2.COLOR_BGR2RGB)
  img = cv2.resize(img, (256, 256))
  final_img.append(img)
       # img = torch.tensor(img).float()

import os
import pandas as pd

df = pd.read_csv("train_COVIDx8A.txt", sep=" ", header=None)

import cv2

img = cv2.imread(df[1][1])
print(img)

data_train_path_10000 = data["PATH"][5000:10000]
data_train_targets_10000 = data["Targets"][5000:10000]
for (i ,j) in zip(data_train_path_10000, data_train_targets_10000):
  label.append(j)
  img = cv2.imread(i)
  img = cv2.cvtColor(img ,cv2.COLOR_BGR2RGB)
  img = cv2.resize(img, (256, 256))
  final_img.append(img)

data_train_path_15000 = data["PATH"][10000:15000]
data_train_targets_15000 = data["Targets"][10000:15000]
for (i ,j) in zip(data_train_path_15000, data_train_targets_15000):
  label.append(j)
  img = cv2.imread(i)
  img = cv2.cvtColor(img ,cv2.COLOR_BGR2RGB)
  img = cv2.resize(img, (256, 256))
  final_img.append(img)

data_train_path_21000 = data["PATH"][15000:21268]
data_train_targets_21000 = data["Targets"][15000:21268]
for (i ,j) in zip(data_train_path_21000, data_train_targets_21000):
  label.append(j)
  img = cv2.imread(i)
  img = cv2.cvtColor(img ,cv2.COLOR_BGR2RGB)
  img = cv2.resize(img, (256, 256))
  final_img.append(img)

final_img = np.array(final_img)

label = np.array(label)

BATCH_SIZE = 32 * strategy.num_replicas_in_sync
print(f"Batch size: {BATCH_SIZE}")
AUTO = tf.data.AUTOTUNE

def scale(image, label):
    image = tf.image.convert_image_dtype(image, tf.float32)
    label = tf.cast(label, tf.int32)
    return image, label

def augment(image,label):
    image = tf.image.resize_with_crop_or_pad(image, 256, 256) # Add 8 pixels of padding
    image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness
    image = tf.clip_by_value(image, 0., 1.)

    return image, label

train_ds = tf.data.Dataset.from_tensor_slices((final_img[:10000], label[:10000]))
train_ds = (
    train_ds
    .shuffle(1024)
    .map(scale, num_parallel_calls=AUTO)
    .map(augment, num_parallel_calls=AUTO)
    .batch(BATCH_SIZE)
    .prefetch(AUTO)
)

test_ds = tf.data.Dataset.from_tensor_slices((final_img[17000:], label[17000:]))
test_ds = (
    test_ds
    .map(scale, num_parallel_calls=AUTO)
    .batch(BATCH_SIZE)
    .prefetch(AUTO)
)

import numpy as np
from keras.callbacks import Callback
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score

class Metrics(tf.keras.callbacks.Callback):
  def __init__(self, valid_data):
    super(Metrics, self).__init__()
    self.validation_data = valid_data

  def on_epoch_end(self, epoch, logs=None):
    logs = logs or {}
    val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)
    val_targ = self.validation_data[1]
    if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:
      val_targ = np.argmax(val_targ, -1)

    _val_f1 = f1_score(val_targ, val_predict, average='macro')
    _val_recall = recall_score(val_targ, val_predict, average='macro')
    _val_precision = precision_score(val_targ, val_predict, average='macro')

    logs['val_f1'] = _val_f1
    logs['val_recall'] = _val_recall
    logs['val_precision'] = _val_precision
    print(" — val_f1: %f — val_precision: %f — val_recall: %f" % (_val_f1, _val_precision, _val_recall))
    return

class SAMModel(tf.keras.Model):
    def __init__(self, resnet_model, rho=0.05):
        """
        p, q = 2 for optimal results as suggested in the paper
        (Section 2)
        """
        super(SAMModel, self).__init__()
        self.resnet_model = resnet_model
        self.rho = rho

    def train_step(self, data):
        (images, labels) = data
        e_ws = []
        with tf.GradientTape() as tape:
            predictions = self.resnet_model(images)
            loss = self.compiled_loss(labels, predictions)
        trainable_params = self.resnet_model.trainable_variables
        gradients = tape.gradient(loss, trainable_params)
        grad_norm = self._grad_norm(gradients)
        scale = self.rho / (grad_norm + 1e-12)
        
        with tf.GradientTape() as tape:
            predictions = self.resnet_model(images)
            loss = self.compiled_loss(labels, predictions)    
        for (grad, param) in zip(gradients, trainable_params):
            e_w = grad * scale
            param.assign_add(e_w)
            e_ws.append(e_w)
        sam_gradients = tape.gradient(loss, trainable_params)
        for (param, e_w) in zip(trainable_params, e_ws):
            param.assign_sub(e_w)
        
        self.optimizer.apply_gradients(
            zip(sam_gradients, trainable_params))

        self.compiled_metrics.update_state(labels, predictions)
        return {m.name: m.result() for m in self.metrics}

    def test_step(self, data):
        (images, labels) = data
        predictions = self.resnet_model(images, training=False)
        loss = self.compiled_loss(labels, predictions)
        self.compiled_metrics.update_state(labels, predictions)
        return {m.name: m.result() for m in self.metrics}

    def _grad_norm(self, gradients):
        norm = tf.norm(
            tf.stack([
                tf.norm(grad) for grad in gradients if grad is not None
            ])
        )
        return norm

train_callbacks = [
    tf.keras.callbacks.EarlyStopping(
        monitor="val_loss", patience=10,
        restore_best_weights=True
    ),
    tf.keras.callbacks.ReduceLROnPlateau(
        monitor="val_loss", factor=0.5,
        patience=3, verbose=1
    )
]

with strategy.scope():
    model = SAMModel(utils.get_training_model())
model.compile(
    optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"]
)
print(f"Total learnable parameters: {model.resnet_model.count_params()/1e6} M")

start = time.time()
history = model.fit(train_ds,
                   validation_data=test_ds,
                   callbacks=[train_callbacks],
                   epochs=25)
print(f"Total training time: {(time.time() - start)/60.} minutes")

acc = history.history['accuracy']

acc[-1]

rf1_l2sam = f1_score()//

